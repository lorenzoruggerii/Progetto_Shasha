{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "635d5e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mesa\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from random import choices\n",
    "from random import randrange\n",
    "import random\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "212bd0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_edges = pd.DataFrame(columns = [\"ID_1\", \"ID_2\", \"TS_start\", \"TS_end\", \"Type\", \"Edge_ID\"])\n",
    "df_nodes = pd.DataFrame(columns = [\"ID\", \"State\", \"Datetime\"])\n",
    "df_properties = pd.DataFrame(columns = [\"ID\", \"Sex\", \"Age\"])\n",
    "\n",
    "num_agents = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30eb0e60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Array utili\n",
    "encounters_prob = {\"wave\": 0.3, \"talk\": 0.2, \"kiss\": 0.05, \"lunch\": 0.025, \"dinner\": 0.025, \"party\": 0.05, \"lecture\": 0.25, \"tango_lesson\": 0.1}\n",
    "edge_id = 0\n",
    "timestamp_start_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98ad8396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def check_times(df, agent_id, timestamp_start, timestamp_end):\n",
    "    global nearest_ts_start_row, df_agent_sorted\n",
    "    \"\"\"This function returns if a certain encounter can be produced\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "        - df: the dataframe containing previous encounters\n",
    "        - agent_id\n",
    "        - timestamps start and end of the newly generated encounter\n",
    "    \n",
    "    \"\"\"\n",
    "    df_agent = df.loc[df[\"ID_1\"]==agent_id,:]\n",
    "    df_agent_sorted = df_agent.sort_values(\"TS_start\")\n",
    "    ts_starts = df_agent_sorted[\"TS_start\"]\n",
    "    nearest_ts_start_row = [i for (i, ts) in enumerate(ts_starts) if timestamp_start > ts][-1]\n",
    "    if timestamp_start > df_agent_sorted.iloc[nearest_ts_start_row][\"TS_end\"]:\n",
    "        ts_ends = df_agent_sorted[\"TS_end\"]\n",
    "        nearest_ts_end_row = [i for (i, ts) in enumerate(ts_ends) if timestamp_end < ts]\n",
    "        if bool(nearest_ts_end_row)==False:\n",
    "            return True\n",
    "        elif timestamp_end < df_agent_sorted.iloc[nearest_ts_end_row[0]][\"TS_start\"]:\n",
    "            return True\n",
    "    return False       \n",
    "         \n",
    "def find_overlaps(df_times_encounter, df_edges, edge_id, enc_type):\n",
    "    global new_row_1, new_row_2, time_starts, time_ends\n",
    "    for i in range(len(df_times_encounter.index)-1):\n",
    "        for j in range(i+1, len(df_times_encounter.index)):\n",
    "            time_starts = [df_times_encounter.iloc[i][\"TS_start\"], df_times_encounter.iloc[j][\"TS_start\"]]\n",
    "            time_ends = [df_times_encounter.iloc[i][\"TS_end\"], df_times_encounter.iloc[j][\"TS_end\"]]\n",
    "            if max(time_starts) < min(time_ends):\n",
    "                new_row_1 = {\"ID_1\": df_times_encounter.iloc[i][\"ID\"], \"ID_2\": df_times_encounter.iloc[j][\"ID\"], \"TS_start\": max(time_starts), \"TS_end\": min(time_ends), \"Type\": enc_type, \"Edge_ID\": edge_id}\n",
    "                df_edges.loc[len(df_edges)] = new_row_1\n",
    "                new_row_2 = {\"ID_1\": df_times_encounter.iloc[j][\"ID\"], \"ID_2\": df_times_encounter.iloc[i][\"ID\"], \"TS_start\": max(time_starts), \"TS_end\": min(time_ends), \"Type\": enc_type, \"Edge_ID\": edge_id}\n",
    "                df_edges.loc[len(df_edges)] = new_row_2\n",
    "    return df_edges\n",
    "\n",
    "def update_states(df_nodes, df_edges, edge_id, timestamp_start, timestamp_end, encounter_type):\n",
    "    global df_edges_last_meeting, agent_states, new_row_states, df_states_after, encounters, sick_exp_people \n",
    "    df_edges_last_meeting = df_edges.loc[df_edges[\"Edge_ID\"]==edge_id]\n",
    "    agents_at_meeting = df_edges_last_meeting[\"ID_1\"].unique()\n",
    "    agent_states = pd.DataFrame(columns = [\"ID\", \"Last_state\"])\n",
    "    for agent_id in agents_at_meeting:\n",
    "        agent_id_states = df_nodes.loc[df_nodes[\"ID\"] == agent_id]\n",
    "        agent_last_state = agent_id_states.loc[agent_id_states[\"Datetime\"] == max(agent_id_states[agent_id_states[\"Datetime\"]<=timestamp_start][\"Datetime\"]), \"State\"].values[0]\n",
    "        new_row_agent_states = {\"ID\": agent_id, \"Last_state\": agent_last_state}\n",
    "        agent_states.loc[len(agent_states)] = new_row_agent_states\n",
    "    for i in range(len(agent_states)):\n",
    "        df_states_after = df_nodes.loc[df_nodes[\"ID\"]==agent_states.iloc[i][\"ID\"]]\n",
    "        df_states_after = df_states_after.loc[df_states_after[\"Datetime\"] >= timestamp_start]\n",
    "        if len(df_states_after) == 0:\n",
    "            if agent_states.iloc[i][\"Last_state\"] == \"healthy\" or agent_states.iloc[i][\"Last_state\"] == \"recovered\":\n",
    "                encounters = df_edges.loc[df_edges[\"ID_1\"]==agent_states.iloc[i][\"ID\"]]\n",
    "                encounters = encounters.loc[encounters[\"Edge_ID\"] == edge_id]\n",
    "                sick_exp_people = pd.DataFrame([p for k, p in encounters.iterrows() if agent_states.loc[agent_states[\"ID\"] == p[\"ID_2\"], \"Last_state\"].values[0] == \"sick\" or agent_states.loc[agent_states[\"ID\"] == p[\"ID_2\"], \"Last_state\"].values[0] == \"exposed\"])\n",
    "                if len(sick_exp_people) != 0:\n",
    "                    total_exposure_time_secs = 0\n",
    "                    for ii, row in sick_exp_people.iterrows():\n",
    "                        total_exposure_time_secs += (row[\"TS_end\"] - row[\"TS_start\"]).total_seconds()\n",
    "                    if agent_states.iloc[i][\"Last_state\"] == \"healthy\":\n",
    "                        prob_h_to_exposed = healthy_to_exp(agent_states.iloc[i][\"ID\"], total_exposure_time_secs, encounter_type)\n",
    "                        new_state = random.choices([\"healthy\", \"exposed\"], weights = (1-prob_h_to_exposed, prob_h_to_exposed), k = 1)[0]\n",
    "                    else:\n",
    "                        prob_r_to_exposed = recovered_to_exp(agent_states.iloc[i][\"ID\"], total_exposure_time_secs, encounter_type)\n",
    "                        new_state = random.choices([\"recovered\", \"exposed\"], weights = (1-prob_r_to_exposed, prob_r_to_exposed), k = 1)[0]\n",
    "                    new_row_state = {\"ID\": agent_states.iloc[i][\"ID\"], \"State\": new_state, \"Datetime\": timestamp_end}\n",
    "                    df_nodes.loc[len(df_nodes)] = new_row_state\n",
    "                    if new_state == \"exposed\":\n",
    "                        nr_days_exposed = min(max(1,np.round(np.random.normal(7, 2, 1))), 1)\n",
    "                        sick_day = timestamp_end + datetime.timedelta(days = int(nr_days_exposed))\n",
    "                        new_row_state = {\"ID\": agent_states.iloc[i][\"ID\"], \"State\": \"sick\", \"Datetime\": sick_day} # CAMBIALO\n",
    "                        df_nodes.loc[len(df_nodes)] = new_row_state\n",
    "                        p_death = 0.01\n",
    "                        is_dead = random.choices([\"dead\", \"recovered\"], weights = (p_death, 1-p_death), k = 1)[0]\n",
    "                        if is_dead == \"dead\":\n",
    "                            nr_days_new_state = min(max(1,np.round(np.random.normal(3, 1, 1))), 1)\n",
    "                        else:\n",
    "                            nr_days_new_state = min(max(1,np.round(np.random.normal(10, 3, 1))), 1)\n",
    "                        new_state_day = sick_day + datetime.timedelta(days = int(nr_days_new_state))\n",
    "                        new_row_state = {\"ID\": agent_states.iloc[i][\"ID\"], \"State\": is_dead, \"Datetime\": new_state_day}\n",
    "                        df_nodes.loc[len(df_nodes)] = new_row_state\n",
    "                else:\n",
    "                    new_row_state = {\"ID\": agent_states.iloc[i][\"ID\"], \"State\": agent_states.iloc[i][\"Last_state\"], \"Datetime\": timestamp_end}\n",
    "                    df_nodes.loc[len(df_nodes)] = new_row_state\n",
    "                    \n",
    "    return df_nodes\n",
    "                        \n",
    "                    # Abbiamo calcolato l'esposizione alle persone malate, ora bisogna calcolare la probabilità che diventi\n",
    "                    # esposto e, se lo diventa, aggiungiamo anche una riga in nodes che definisce quando diventerà malato.\n",
    "                    # Il discorso del morto lo aggiungiamo dopo nel malato\n",
    "                    # Poi restano da definire gli altri stati: se è esposto non fa nulla e anche se è malato e se uno è recovered\n",
    "                    # la probabilità di tornare malato cambia\n",
    "                \n",
    "        \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87e13439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Distribuzioni di probabilità\n",
    "\n",
    "def encounters_number_dist(N, enc_type):\n",
    "    if enc_type == \"kiss\":\n",
    "        return 2\n",
    "    elif enc_type == \"wave\":\n",
    "        return 2\n",
    "    elif enc_type == \"talk\":\n",
    "        return min(max(2,round(N/5)), 10)\n",
    "    elif enc_type == \"party\":\n",
    "        return min(max(2,round(N/1)), 50)\n",
    "    elif enc_type == \"lunch\":\n",
    "        return min(max(2,round(N/2)), 10) \n",
    "    elif enc_type == \"dinner\":\n",
    "        return min(max(2,round(N/2)), 10)\n",
    "    elif enc_type == \"lecture\":\n",
    "        return min(max(2,round(N/2)), 30)\n",
    "    elif enc_type == \"tango_lesson\":\n",
    "        return min(max(2,round(N/3)), 20)\n",
    "    \n",
    "def duration_dist(enc_type):\n",
    "    \"\"\"Given the encounter type returns the duration in seconds\"\"\"\n",
    "    if enc_type == \"kiss\":\n",
    "        return min(max(10, np.round(np.random.normal(15, 1, 1))), 120)\n",
    "    elif enc_type == \"wave\":\n",
    "        return min(max(30, np.round(np.random.normal(45, 1, 1))), 60)\n",
    "    elif enc_type == \"talk\":\n",
    "        return min(max(60, np.round(np.random.normal(600, 50, 1))), 2400)\n",
    "    elif enc_type == \"party\":\n",
    "        return min(max(3600, np.round(np.random.normal(3*3600, 3600, 1))), 6*3600)\n",
    "    elif enc_type == \"lunch\":\n",
    "        return min(max(600, np.round(np.random.normal(3600, 1800, 1))), 3600*3)\n",
    "    elif enc_type == \"dinner\":\n",
    "        return min(max(600, np.round(np.random.normal(3600, 1800, 1))), 3600*3)\n",
    "    elif enc_type == \"lecture\":\n",
    "        return min(max(3600, np.round(np.random.normal(3600*2, 3600, 1))), 3600*6)\n",
    "    elif enc_type == \"tango_lesson\":\n",
    "        return min(max(1800, np.round(np.random.normal(3600, 600, 1))), 3600*2)\n",
    "    \n",
    "def delay_timestamp_start_end(enc_type, timestamp_start, timestamp_end):\n",
    "    if enc_type == \"kiss\":\n",
    "        return timestamp_start, timestamp_end\n",
    "    elif enc_type == \"wave\":\n",
    "        return timestamp_start, timestamp_end\n",
    "    elif enc_type == \"talk\":\n",
    "        early_late = random.choice([\"early\", \"late\"])\n",
    "        if early_late == \"early\":\n",
    "            return timestamp_start, timestamp_end\n",
    "        else:\n",
    "            timestamp_start_new = timestamp_start + datetime.timedelta(seconds = int(np.random.uniform(0, 300)))\n",
    "            timestamp_end_new = timestamp_end - datetime.timedelta(seconds = int(np.random.uniform(0, 300)))\n",
    "            return timestamp_start_new, timestamp_end_new\n",
    "    elif enc_type == \"party\":\n",
    "        early_late = random.choice([\"early\", \"late\"])\n",
    "        if early_late == \"early\":\n",
    "            return timestamp_start, timestamp_end\n",
    "        else:\n",
    "            timestamp_start_new = timestamp_start + datetime.timedelta(seconds = int(np.random.uniform(0, 3600)))\n",
    "            timestamp_end_new = timestamp_end - datetime.timedelta(seconds = int(np.random.uniform(0, 5400)))\n",
    "            return timestamp_start_new, timestamp_end_new\n",
    "    elif enc_type == \"lunch\":\n",
    "        early_late = random.choice([\"early\", \"late\"])\n",
    "        if early_late == \"early\":\n",
    "            return timestamp_start, timestamp_end\n",
    "        else:\n",
    "            timestamp_start_new = timestamp_start + datetime.timedelta(seconds = int(np.random.uniform(0, 600)))\n",
    "            timestamp_end_new = timestamp_end - datetime.timedelta(seconds = int(np.random.uniform(0, 1800)))\n",
    "            return timestamp_start_new, timestamp_end_new\n",
    "    elif enc_type == \"dinner\":\n",
    "        early_late = random.choice([\"early\", \"late\"])\n",
    "        if early_late == \"early\":\n",
    "            return timestamp_start, timestamp_end\n",
    "        else:\n",
    "            timestamp_start_new = timestamp_start + datetime.timedelta(seconds = int(np.random.uniform(0, 600)))\n",
    "            timestamp_end_new = timestamp_end - datetime.timedelta(seconds = int(np.random.uniform(0, 1800)))\n",
    "            return timestamp_start_new, timestamp_end_new\n",
    "    elif enc_type == \"lecture\":\n",
    "        early_late = random.choice([\"early\", \"late\"])\n",
    "        if early_late == \"early\":\n",
    "            return timestamp_start, timestamp_end\n",
    "        else:\n",
    "            timestamp_start_new = timestamp_start + datetime.timedelta(seconds = int(np.random.uniform(0, 3600)))\n",
    "            timestamp_end_new = timestamp_end - datetime.timedelta(seconds = int(np.random.uniform(0, 600)))\n",
    "            return timestamp_start_new, timestamp_end_new\n",
    "    elif enc_type == \"tango_lesson\":\n",
    "        early_late = random.choice([\"early\", \"late\"])\n",
    "        if early_late == \"early\":\n",
    "            return timestamp_start, timestamp_end\n",
    "        else:\n",
    "            timestamp_start_new = timestamp_start + datetime.timedelta(seconds = int(np.random.uniform(0, 300)))\n",
    "            timestamp_end_new = timestamp_end - datetime.timedelta(seconds = int(np.random.uniform(0, 300)))\n",
    "            return timestamp_start_new, timestamp_end_new\n",
    "    \n",
    "def healthy_to_exp(agent_id, total_exposure_time, enc_type):\n",
    "    age = df_properties.loc[df_properties[\"ID\"]==agent_id, \"Age\"]\n",
    "    if enc_type == \"kiss\":\n",
    "        return 0.5 + 0.4*total_exposure_time/120\n",
    "    elif enc_type == \"wave\":\n",
    "        return 0.1 + 0.2*total_exposure_time/60\n",
    "    elif enc_type == \"talk\":\n",
    "        return 0.4 + 0.3*total_exposure_time/2400\n",
    "    elif enc_type == \"party\":\n",
    "        return 0.6 + 0.4*total_exposure_time/(6*3600)\n",
    "    elif enc_type == \"lunch\":\n",
    "        return 0.3 + 0.2*total_exposure_time/(3600*3)\n",
    "    elif enc_type == \"dinner\":\n",
    "        return 0.3 + 0.2*total_exposure_time/(3600*3)\n",
    "    elif enc_type == \"lecture\":\n",
    "        return 0.4 + 0.4*total_exposure_time/(3600*6)\n",
    "    elif enc_type == \"tango_lesson\":\n",
    "        return 0.5 + 0.4*total_exposure_time/(3600*2)\n",
    "    \n",
    "def recovered_to_exp(agent_id, total_exposure_time, enc_type):\n",
    "    age = df_properties.loc[df_properties[\"ID\"]==agent_id, \"Age\"]\n",
    "    if enc_type == \"kiss\":\n",
    "        return 0.4 + 0.4*total_exposure_time/120\n",
    "    elif enc_type == \"wave\":\n",
    "        return 0.0 + 0.2*total_exposure_time/60\n",
    "    elif enc_type == \"talk\":\n",
    "        return 0.2 + 0.3*total_exposure_time/2400\n",
    "    elif enc_type == \"party\":\n",
    "        return 0.5 + 0.4*total_exposure_time/(6*3600)\n",
    "    elif enc_type == \"lunch\":\n",
    "        return 0.2 + 0.2*total_exposure_time/(3600*3)\n",
    "    elif enc_type == \"dinner\":\n",
    "        return 0.2 + 0.2*total_exposure_time/(3600*3)\n",
    "    elif enc_type == \"lecture\":\n",
    "        return 0.3 + 0.4*total_exposure_time/(3600*6)\n",
    "    elif enc_type == \"tango_lesson\":\n",
    "        return 0.3 + 0.4*total_exposure_time/(3600*2)\n",
    "     \n",
    "        \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94138ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoneyAgent(mesa.Agent):\n",
    "    def __init__(self, unique_id, model, sex, age, state):\n",
    "        super().__init__(unique_id, model)\n",
    "        self.sex = sex\n",
    "        self.age = age\n",
    "        self.state = state\n",
    "        \n",
    "        # self.counter = 0 if self.state == \"healthy\" else 7\n",
    "        \n",
    "    def step(self):\n",
    "        global edge_id, df_nodes, df_edges, df_states_self, timestamp_start_ref, self_last_state_date, timestamp_end, duration, df_times_encounter, df_states_agent, encounter_type, timestamp_start_enc, timestamp_end_enc, num_agents_encountered, i\n",
    "        edge_id += 1\n",
    "        encounter_type = random.choices(list(encounters_prob.keys()), list(encounters_prob.values()), k = 1)[0]\n",
    "        num_agents_encountered = encounters_number_dist(num_agents, encounter_type)\n",
    "        timestamp_start_ref = max(df_edges.loc[df_edges[\"ID_1\"]==self.unique_id, \"TS_end\"]) + datetime.timedelta(hours=1)\n",
    "        df_states_self = df_nodes.loc[df_nodes[\"ID\"] == self.unique_id, [\"State\", \"Datetime\"]]\n",
    "        if str(type(df_states_self)) == \"<class 'pandas.core.series.Series'>\":\n",
    "            df_states_self = pd.DataFrame([df_states_self.values], columns = df_states_self.index)\n",
    "        self_last_state_date = df_states_self.loc[df_states_self[\"Datetime\"] == max(df_states_self[df_states_self[\"Datetime\"]<=timestamp_start_ref][\"Datetime\"])][[\"State\", \"Datetime\"]]\n",
    "        if self_last_state_date[\"State\"].values[0] != \"dead\": \n",
    "            duration = duration_dist(encounter_type)\n",
    "            timestamp_end = timestamp_start_ref + datetime.timedelta(seconds = int(duration))\n",
    "            df_states_self = df_nodes.loc[df_nodes[\"ID\"] == self.unique_id, [\"State\", \"Datetime\"]]\n",
    "            if str(type(df_states_self)) == \"<class 'pandas.core.series.Series'>\":\n",
    "                df_states_self = pd.DataFrame([df_states_self.values], columns = df_states_self.index)\n",
    "            self_last_state_date = df_states_self.loc[df_states_self[\"Datetime\"] == max(df_states_self[df_states_self[\"Datetime\"]<=timestamp_end][\"Datetime\"])][[\"State\", \"Datetime\"]]\n",
    "            if self_last_state_date[\"State\"].values[0] != \"dead\":\n",
    "                # Verifica se è possibile l'incontro per self \n",
    "                if check_times(df_edges, self.unique_id, timestamp_start_ref, timestamp_end):\n",
    "                    df_times_encounter = pd.DataFrame(columns = [\"ID\", \"TS_start\", \"TS_end\"])\n",
    "                    new_row_edge_id = {\"ID\": self.unique_id, \"TS_start\": timestamp_start_ref, \"TS_end\": timestamp_end}\n",
    "                    df_times_encounter.loc[len(df_times_encounter)] = new_row_edge_id\n",
    "                    agents_encountered = [] # lista degli agenti incontrati (pesco da agents_list)\n",
    "                    i = 0\n",
    "                    agents_list_2 = []\n",
    "                    # Prendo gli id degli agenti\n",
    "                    agents_list = [a for a in self.model.schedule.agents if a!=self] # lista degli agenti pescabili\n",
    "                    for ag in agents_list:\n",
    "                        df_states_agent = df_nodes[df_nodes[\"ID\"]==ag.unique_id][[\"State\", \"Datetime\"]]\n",
    "                        agent_last_state_2_before = df_states_agent[df_states_agent[\"Datetime\"] == max(df_states_agent[df_states_agent[\"Datetime\"]<=timestamp_start_ref][\"Datetime\"])][\"State\"].values[0]\n",
    "                        agent_last_state_2_after = df_states_agent[df_states_agent[\"Datetime\"] == max(df_states_agent[df_states_agent[\"Datetime\"]<=timestamp_end][\"Datetime\"])][\"State\"].values[0]\n",
    "                        if agent_last_state_2_before != \"dead\" and agent_last_state_2_after != \"dead\":\n",
    "                            agents_list_2.append(ag)\n",
    "                    # se è possibile l'incontro per self allora pesca a caso gli agenti\n",
    "                    while i<num_agents_encountered-1 and len(agents_list_2)!=0:\n",
    "                        other_agent = self.random.choice(agents_list_2)\n",
    "                        agents_list_2.remove(other_agent)\n",
    "                        agents_encountered.append(other_agent)\n",
    "                        timestamp_start_enc, timestamp_end_enc = delay_timestamp_start_end(encounter_type, timestamp_start_ref, timestamp_end)\n",
    "                        # verifica se è possibile l'incontro per entrambi gli agenti guardando se è compredo tra due incontri già presenti\n",
    "                        if check_times(df_edges, other_agent.unique_id, timestamp_start_enc, timestamp_end_enc):\n",
    "                            # Popoliamo il dataframe relativo all'incontro\n",
    "                            new_row_edge_id = {\"ID\": other_agent.unique_id, \"TS_start\": timestamp_start_enc, \"TS_end\": timestamp_end_enc} \n",
    "                            df_times_encounter.loc[len(df_times_encounter)] = new_row_edge_id\n",
    "                            i += 1    \n",
    "                    if i>=num_agents_encountered/2: # Se il numero di agenti incontrati è soddisfacente allora genera incontro\n",
    "                        df_edges = find_overlaps(df_times_encounter, df_edges, edge_id, encounter_type)\n",
    "                        # Qui l'incontro è stato generato, quindi sistemiamo gli stati\n",
    "                        df_nodes = update_states(df_nodes, df_edges, edge_id, timestamp_start_ref, timestamp_end, encounter_type)\n",
    "                        # Sistemati gli stati\n",
    "\n",
    "                    # Mancano tutte le distribuzioni di probabilità per nr di persone incontrate, nr. incontri, timestamps deviati\n",
    "                    # rispetto a quelli principali e probabilità dei passaggi di stato\n",
    "                    # Manca soprattutto modellare i passaggi di stato\n",
    "                    # Ricordati che per ogni agente il timestamp iniziale (da quando devi generare gli incontri) corrisponde\n",
    "                    # al suo ultimo passaggio di stato (da salvare nel dataframe nodes)\n",
    "                    # AGGIORNA EDGEID\n",
    "                    # Crea il dataframe vuoto df_edges\n",
    "                    # Crea il dataframe con le proprietà degli agenti\n",
    "\n",
    "                \n",
    "                  \n",
    "class MoneyModel(mesa.Model):\n",
    "    def __init__(self, N):\n",
    "        global df_properties, df_nodes, df_edges\n",
    "        self.num_agents = N\n",
    "        self.schedule = mesa.time.RandomActivation(self)\n",
    "        ages = random.choices(range(10, 80), k=self.num_agents)\n",
    "        diseases = random.choices([\"sick\", \"healthy\"], k=self.num_agents)\n",
    "        sexs = random.choices([\"female\", \"male\"], k=self.num_agents)\n",
    "        # Creating agents\n",
    "        for i in range(self.num_agents):\n",
    "            a = MoneyAgent(i, self, sexs[i], ages[i], diseases[i])\n",
    "            self.schedule.add(a)\n",
    "            new_row_df_properties = {\"ID\": i, \"Sex\": a.sex, \"Age\": a.age}\n",
    "            df_properties = df_properties.append(new_row_df_properties, ignore_index = True)\n",
    "            new_row_df_nodes = {\"ID\": i, \"State\": a.state, \"Datetime\": datetime.datetime(2020, 1, 1, 8, 0, 0)}\n",
    "            df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n",
    "            new_row_df_edges = {\"ID_1\": i, \"ID_2\": i, \"TS_start\": datetime.datetime(2020, 1, 1, 8, 0, 0), \"TS_end\": datetime.datetime(2020, 1, 1, 8, 0, 0), \"Type\": \"INIT\", \"Edge_ID\": \"INIT\"}\n",
    "            df_edges = df_edges.append(new_row_df_edges, ignore_index = True)\n",
    "            if a.state == \"sick\":\n",
    "                nr_days_recovering = min(max(7,np.round(np.random.normal(10, 3, 1))), 14)\n",
    "                new_state_day = datetime.datetime(2020, 1, 1, 8, 0, 0) + datetime.timedelta(days = int(nr_days_recovering))\n",
    "                new_row_df_nodes = {\"ID\": i, \"State\": \"recovered\", \"Datetime\": new_state_day}\n",
    "                df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n",
    "                \n",
    "    def step(self):\n",
    "        self.schedule.step()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dead71b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48/2727201778.py:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_properties = df_properties.append(new_row_df_properties, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_edges = df_edges.append(new_row_df_edges, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_properties = df_properties.append(new_row_df_properties, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_edges = df_edges.append(new_row_df_edges, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_properties = df_properties.append(new_row_df_properties, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_edges = df_edges.append(new_row_df_edges, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_properties = df_properties.append(new_row_df_properties, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_edges = df_edges.append(new_row_df_edges, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_properties = df_properties.append(new_row_df_properties, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_edges = df_edges.append(new_row_df_edges, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_properties = df_properties.append(new_row_df_properties, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_edges = df_edges.append(new_row_df_edges, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_properties = df_properties.append(new_row_df_properties, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_edges = df_edges.append(new_row_df_edges, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_properties = df_properties.append(new_row_df_properties, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_edges = df_edges.append(new_row_df_edges, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_properties = df_properties.append(new_row_df_properties, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_edges = df_edges.append(new_row_df_edges, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_properties = df_properties.append(new_row_df_properties, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_edges = df_edges.append(new_row_df_edges, ignore_index = True)\n",
      "/tmp/ipykernel_48/2727201778.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_nodes = df_nodes.append(new_row_df_nodes, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "steps = 100\n",
    "empty_model = MoneyModel(num_agents)\n",
    "for i in range(steps):\n",
    "    empty_model.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93e45cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>State</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>7</td>\n",
       "      <td>dead</td>\n",
       "      <td>2020-01-19 12:28:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>8</td>\n",
       "      <td>dead</td>\n",
       "      <td>2020-02-05 00:38:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID State            Datetime\n",
       "228  7  dead 2020-01-19 12:28:10\n",
       "476  8  dead 2020-02-05 00:38:58"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes[df_nodes[\"State\"]==\"dead\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33ef9cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_1</th>\n",
       "      <th>ID_2</th>\n",
       "      <th>TS_start</th>\n",
       "      <th>TS_end</th>\n",
       "      <th>Type</th>\n",
       "      <th>Edge_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>INIT</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>INIT</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>INIT</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>INIT</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>INIT</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9557</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-05 04:18:37</td>\n",
       "      <td>2020-02-05 04:27:33</td>\n",
       "      <td>talk</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9558</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-02-05 06:57:48</td>\n",
       "      <td>2020-02-05 07:00:41</td>\n",
       "      <td>talk</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9559</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-02-05 06:57:48</td>\n",
       "      <td>2020-02-05 07:00:41</td>\n",
       "      <td>talk</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-02-05 07:59:15</td>\n",
       "      <td>2020-02-05 07:59:59</td>\n",
       "      <td>wave</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-02-05 07:59:15</td>\n",
       "      <td>2020-02-05 07:59:59</td>\n",
       "      <td>wave</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9562 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID_1 ID_2            TS_start              TS_end  Type Edge_ID\n",
       "0       0    0 2020-01-01 08:00:00 2020-01-01 08:00:00  INIT    INIT\n",
       "1       1    1 2020-01-01 08:00:00 2020-01-01 08:00:00  INIT    INIT\n",
       "2       2    2 2020-01-01 08:00:00 2020-01-01 08:00:00  INIT    INIT\n",
       "3       3    3 2020-01-01 08:00:00 2020-01-01 08:00:00  INIT    INIT\n",
       "4       4    4 2020-01-01 08:00:00 2020-01-01 08:00:00  INIT    INIT\n",
       "...   ...  ...                 ...                 ...   ...     ...\n",
       "9557    5    0 2020-02-05 04:18:37 2020-02-05 04:27:33  talk     998\n",
       "9558    3    6 2020-02-05 06:57:48 2020-02-05 07:00:41  talk     999\n",
       "9559    6    3 2020-02-05 06:57:48 2020-02-05 07:00:41  talk     999\n",
       "9560    9    5 2020-02-05 07:59:15 2020-02-05 07:59:59  wave    1000\n",
       "9561    5    9 2020-02-05 07:59:15 2020-02-05 07:59:59  wave    1000\n",
       "\n",
       "[9562 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b29ed40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_1</th>\n",
       "      <th>ID_2</th>\n",
       "      <th>TS_start</th>\n",
       "      <th>TS_end</th>\n",
       "      <th>Type</th>\n",
       "      <th>Edge_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>INIT</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>INIT</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>INIT</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>INIT</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>INIT</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9557</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-05 04:18:37</td>\n",
       "      <td>2020-02-05 04:27:33</td>\n",
       "      <td>talk</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9558</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-02-05 06:57:48</td>\n",
       "      <td>2020-02-05 07:00:41</td>\n",
       "      <td>talk</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9559</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-02-05 06:57:48</td>\n",
       "      <td>2020-02-05 07:00:41</td>\n",
       "      <td>talk</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-02-05 07:59:15</td>\n",
       "      <td>2020-02-05 07:59:59</td>\n",
       "      <td>wave</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-02-05 07:59:15</td>\n",
       "      <td>2020-02-05 07:59:59</td>\n",
       "      <td>wave</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9562 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID_1 ID_2            TS_start              TS_end  Type Edge_ID\n",
       "0       0    0 2020-01-01 08:00:00 2020-01-01 08:00:00  INIT    INIT\n",
       "1       1    1 2020-01-01 08:00:00 2020-01-01 08:00:00  INIT    INIT\n",
       "2       2    2 2020-01-01 08:00:00 2020-01-01 08:00:00  INIT    INIT\n",
       "3       3    3 2020-01-01 08:00:00 2020-01-01 08:00:00  INIT    INIT\n",
       "4       4    4 2020-01-01 08:00:00 2020-01-01 08:00:00  INIT    INIT\n",
       "...   ...  ...                 ...                 ...   ...     ...\n",
       "9557    5    0 2020-02-05 04:18:37 2020-02-05 04:27:33  talk     998\n",
       "9558    3    6 2020-02-05 06:57:48 2020-02-05 07:00:41  talk     999\n",
       "9559    6    3 2020-02-05 06:57:48 2020-02-05 07:00:41  talk     999\n",
       "9560    9    5 2020-02-05 07:59:15 2020-02-05 07:59:59  wave    1000\n",
       "9561    5    9 2020-02-05 07:59:15 2020-02-05 07:59:59  wave    1000\n",
       "\n",
       "[9562 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cef9a717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exposed'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_last_state_date[\"State\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7f5421cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_last_state_date[\"State\"].values[0] != \"dead\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0a849539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-03 01:13:41')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_start_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e035fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges.to_csv(\"tNodeEmbed/data/Meetings/edges_1_prova.csv\",columns = list(df_edges.columns), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe5f2866",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes.to_csv(\"tNodeEmbed/data/Meetings/nodes_1_prova.csv\",columns = list(df_nodes.columns), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04862d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
